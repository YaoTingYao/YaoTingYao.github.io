<!DOCTYPE HTML>

<html>
	<head>
		<title>Deep Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main0.css" />
	</head>
	<body class="is-preload">
		<div id="body-container">


				<!-- Main -->
					<div id="main">
						<div class="inner">
							<!-- Content -->
								<section>
									<header>
										<a href="index.html" class="button">Back</a>

										</br>
										</br>
										<h1 style="color: black font-weight: 400; " align="left">Cropland Maps on Planet-Scope Imagery Using U-Net at National Scales in Zambia</h1>
									</header>
									<p style= "font-size: 0.8em; text-align:left;">Yao-Ting Yao<br>Advisor: Lyndon Estes, Sitian Xiong<br>Master Thesis</p>

									<p>Cropland mapping is a crucial tool for evaluating food security. Crop fields in sub-Saharan
African countries expect to expand by more than three times in the next decade to satisfy food
demand. Developing accurate, large-area cropland maps of Africa’s smallholder agricultural
systems is critical.</p>
									<p>To address this need, this research use U-Net, a convolutional neural network, to map
cropland for the year 2022 in the Republic of Zambia, a country undergoing rapid agricultural
growth.</p>


									<hr class="major" />
									<h2 style="color:#e48bae;">Created a labeling platform and workflow protocol on Google Earth Engine (GEE)</h2>
									<p>A grid of 200 by 200 was generated to cover the entire region of Zambia. A catalog was created, using R script to randomly seed 600 labels in each agriculture zone. High spatial-resolution satellite imagery grids of the growing and off seasons were obtained from Planet-Scope (with a resolution of 2.77m), along with NDVI imagery. These were utilized to create labels for training and evaluating the model, resulting in 921 labels for Zambia and the 5,377 labels from three other African countries (Kenya, Tanzania, Ghana, and the Republic of Congo).</p>
									<span class="image main"><img src="images/gee.png" alt="" /></span>
                  <p>The Google Earth Engine (GEE) API was utilized to develop a set of automation tools that involved <a href="https://colab.research.google.com/drive/1ZZg_OdoOSVGRepmwEL4Tgs0ixQXpefiv">rasterization of labels</a> into three distinct classes, non-field(class_0), field(class_1), and field boundary(class_2). In addition, an <a href="https://colab.research.google.com/drive/1ZZg_OdoOSVGRepmwEL4Tgs0ixQXpefiv"> imagery downloader </a> and <a href="https://colab.research.google.com/drive/1f4h51ebbrwd7mlIJSK2_LFI6H8LHtzRA"> resampler </a>were also created using the same API. Also created <a href=" https://colab.research.google.com/drive/1Z89SPz1c1rSoJXakkCDfH2p2b_eEXY8G#scrollTo=wh1KRswT5dNk "> check tool </a>to check if files are missing in the folder and needed to be reloaded.</p>
									<span class="image main"><img src="images/gee_api.png" alt="" /></span>


									<hr class="major" />
									<h2 style="color:#e48bae;">Attention U-Net: model fitting, validation and evaluation</h2>
									<p>The U-Net architecture is considered one of the advanced frameworks for convolutional neural network (CNN) based image segmentation. This model includes an encoder path and a decoder path with a U-shape construction, which leads to a reduction in the spatial scale after consecutive pooling operations, followed by an increase in the contracting path. To enhance the performance of the model, Attention U-Net was utilized in this research, which actively suppresses activations in irrelevant regions and reduces the number of redundant features, thereby optimizing computational resources. Pytorch and scikit-learn libraries were employed to train the model and make predictions for the results.</p>
									<span class="image main"><img src="images/unet.png" alt="" /></span>

									<p>Before model training, create the Pickle train and validation dataset. Pickle is a useful Python tool helps to save the model and to minimize lengthy re-train. It saves configs, e.g., data path, label patch size, and side buffer, training transformation type as well. The label size is 200 by 200 with 12 pixel buffer with 0 value and the planet scope imagery is 224 by 224. 80% of the collected labels used for training and 20% for validation. </p>
									<div id="banner">
									    <div class="inline-block">
									        <img src ="images/field1.png" width="200" height="200">
									    </div>

									    <div class="inline-block">
									        <img src ="images/field2.png" width="200" height="200">
									    </div>

									    <div class="inline-block">
									        <img src ="images/field3.png" width="200" height="200">
									    </div>
									</div>
									<p>The dimensions of the label size are 200 by 200, with a 12-pixel buffer that has a value of 0, while the planet scope imagery is 224 by 224. 80% of the accumulated labels are allocated for training purposes, while the remaining 20% are designated for validation purposes. Prior to commencing the training of the model, it is imperative to generate the Pickle train and validation dataset. The Pickle utility in Python is a valuable tool that facilitates the preservation of the model and helps to mitigate the need for extensive retraining. This tool is adept at storing critical configurations such as the data path, label patch size, side buffer, and training transformation type. </p>
                  <p>For model fitting and evaluating processes, using the model compiler helps to reduce system load and improve performance. Choose nesterov accelerated gradient optimizer to faster weights and biases adjustment processes in a smaller number of epochs comparing with momentum optimization technique. The hyper-parameters used in train, validation and evaluating in this research are as follows:</p>
										<ul>
                     <li>Train batch size : 32</li>
                     <li>Validation batch size : 2</li>
                     <li>Epochs : 300</li>
										 <li>Dropout rate: 0.15 (model fitting); 0.1 (prediction)</li>
										 <li>Learning rate: 0.01 (using polynomial learning rate decay as learning rate policy)</li>
                  </ul>

									<hr class="major" />
									<h2 style="color:#e48bae;">Prediction: using hyper-parameters to smooth edge effect</h2>
									<p>The prediction hyper-parameters are as follows:</p>
									<ul>
									 <li>Prediction patch size: 250</li>
									 <li>Prediction buffer: 179</li>
									 <li>Composite buffer: 179</li>
									 <li>Prediction batch: 2</li>
									 <li>Shrink pixels: 54</li>
									 <li>Number of MC trials: 10</li>
									</ul>
									<p>The input image is 2358 by 2358 pixels. The <b>patch size</b> of 250 pixels means that the input image is divided into smaller patches of this size. Setting up buffer helps us to work with <b>edge effects</b>. The <b>prediction buffer</b> of 179 pixels is used to ensure that the output image has smooth transitions between neighboring patches. This means that when a patch is processed, the model will also predict an additional buffer of 179 pixels around the edges of the patch. This buffer ensures that the model can capture the context around the edges of the patch and avoids any sharp edges in the output image where the patches are stitched together. </p>
                  <p>The <b>composite buffer</b> of 179 pixels is used to ensure that the final output image has smooth transitions between all the patches. This means that when the patches are stitched together, an additional buffer of 179 pixels is added around the edges of each patch to ensure that there are no sharp edges or artifacts in the final output image. After ,shrink pixels. As a result, the final prediction dimension is 2000 by 2000.</p>
                  <p>In the prediction processes, we use model <b>drop out </b>and <b>Monte Carlo dropout (MC)</b> to improve the robustness of the model's predictions. During prediction, dropout is usually turned off. However, according to Sam Khallaghi and Lyndon Estes‘s research, when setting up dropout rate in 0.1, the prediction has better result. The number of MC trials specifies how many times the model should be run with dropout enabled and averaged.  </p>


								</section>
								<!-- Footer -->
									<div id="footer">
										<script>
									var today = new Date();
									var year = today.getFullYear();
									document.writeln("Copyright &copy; " + year+" - Yao-Ting Yao");
										 </script>
									</div>
						</div>
					</div>
      </div>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
