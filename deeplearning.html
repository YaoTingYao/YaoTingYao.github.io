<!DOCTYPE HTML>

<html>
	<head>
		<title>Deep Learning</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main0.css" />
	</head>
	<body class="is-preload">
		<div id="body-container">


				<!-- Main -->
					<div id="main">
						<div class="inner">
							<!-- Content -->
								<section>
									<header>
										<a href="index.html" class="button">Back</a>

										</br>
										</br>
										<h1 style="color: black font-weight: 400; " align="left">Cropland Maps on Planet-Scope Imagery Using U-Net at National Scales in Zambia</h1>
									</header>
									<p style= "font-size: 0.8em; text-align:left;">Yao-Ting Yao<br>Advisor: Lyndon Estes, Sitian Xiong<br>Master Thesis</p>

									<p>Cropland mapping is a crucial tool for evaluating food security. Crop fields in sub-Saharan
African countries expect to expand by more than three times in the next decade to satisfy food
demand. Developing accurate, large-area cropland maps of Africaâ€™s smallholder agricultural
systems is critical.</p>
									<p>To address this need, this research use U-Net, a convolutional neural network, to map
cropland for the year 2022 in the Republic of Zambia, a country undergoing rapid agricultural
growth.</p>


									<hr class="major" />
									<h2 style="color:#e48bae;">Created a labeling platform and workflow protocol on Google Earth Engine (GEE)</h2>
									<p>A grid of 200 by 200 was generated to cover the entire region of Zambia. A catalog was created, using R script to randomly seed 600 labels in each agriculture zone. High spatial-resolution satellite imagery grids of the growing and off seasons were obtained from Planet-Scope (with a resolution of 2.77m), along with NDVI imagery. These were utilized to create labels for training and evaluating the model, resulting in 921 labels for Zambia and the 5,377 labels from three other African countries (Kenya, Tanzania, Ghana, and the Republic of Congo).</p>
									<span class="image main"><img src="images/gee.png" alt="" /></span>
                  <p>The Google Earth Engine (GEE) API was utilized to develop a set of automation tools that involved <a href="https://colab.research.google.com/drive/1ZZg_OdoOSVGRepmwEL4Tgs0ixQXpefiv">rasterization of labels</a> into three distinct classes, non-field(class_0), field(class_1), and field boundary(class_2). In addition, an <a href="https://colab.research.google.com/drive/1ZZg_OdoOSVGRepmwEL4Tgs0ixQXpefiv"> imagery downloader </a> and <a href="https://colab.research.google.com/drive/1f4h51ebbrwd7mlIJSK2_LFI6H8LHtzRA"> resampler </a>were also created using the same API. Also created <a href=" https://colab.research.google.com/drive/1Z89SPz1c1rSoJXakkCDfH2p2b_eEXY8G#scrollTo=wh1KRswT5dNk "> check tool </a>to check if files are missing in the folder and needed to be reloaded.</p>
									<span class="image main"><img src="images/gee_api.png" alt="" /></span>


									<hr class="major" />

									<h2 style="color:#e48bae;">Model Training, Validation and Pridiction</h2>
									<p>We trained the model to
recognize three classes (field, non-field, and field boundary) for 200 epochs, using 80% of the
collected labels for training and 20% for validation, resulting in an F1 score of 0.66 for the field
interior class. We then fine-tuned the model on the labels for Zambia (F1 = 0.69), and the
mapped the predictions for the field interior class for the entire country and passed these
through a final segmentation step to convert the binary predictions into individual fields.</p>
									<div id="banner">
									    <div class="inline-block">
									        <img src ="images/field1.png" width="200" height="200">
									    </div>

									    <div class="inline-block">
									        <img src ="images/field2.png" width="200" height="200">
									    </div>

									    <div class="inline-block">
									        <img src ="images/field3.png" width="200" height="200">
									    </div>
									</div>
									<p>     U-Net is one of the cutting-edge architectures of CNN for image segmentation. U-Net has U-shape construction path (encoder) and an expansion path (decoder) structure, in which the spatial scale is subsequently reduced after consecutive pooling operations and increased in a contracting path. This research use Pytorch and scikit-learn library to train model and predict results. </p>
									<span class="image main"><img src="images/unet.png" alt="" /></span>
                  <p>The
results demonstrate the value of applying neural network-based approaches with new sources
of high resolution imagery for cropland mapping because of its ability to detect individual fields
more effectively than approaches previously used to map Zambia (e.g. Random Forests). Future
opportunities exist to improve the model by collecting labels that better balancing the number
of labels among different classes, which includes improving the number of non-field labels on
landscapes that lead to false positives (e.g., wetland areas). In addition to improving the overall
accuracy, the maps provide additional valuable information on field size, which can be used to
understand the characteristics of the agricultural system. </p>
                  <span class="image main"><img src="images/model.png" alt="" /></span>
									<div id="banner">
									    <div class="inline-block">
									        <img src ="images/prediction3.png" width="350" height="350">
									    </div>

									    <div class="inline-block">
									        <img src ="images/prediction4.png" width="350" height="350">
									    </div>
									</div>

								</section>
								<!-- Footer -->
									<div id="footer">
										<script>
									var today = new Date();
									var year = today.getFullYear();
									document.writeln("Copyright &copy; " + year+" - Yao-Ting Yao");
										 </script>
									</div>
						</div>
					</div>
      </div>


		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
